![Voice Agent Diagram](./1.pdf)

Requirements:

	â€¢	Python 3.10
	â€¢	ffmpeg (for Whisper)
	â€¢	Installed Python packages from requirements.txt
	â€¢	Ollama (installed and running)
	â€¢	Downloaded model: mistral (or another model of your choice)

 Model Setup:

        You need to have the Mistral model available in Ollama:  
        ollama run mistral
        You can leave this running in a separate terminal window, or start the Ollama server:
        ollama serve

ğŸ§ How it works:

	1.	ğŸ™ï¸ Records 5 seconds of audio from your microphone
	2.	ğŸ§  Transcribes it using Whisper locally
	3.	ğŸ’¬ Sends the transcribed text to a local Mistral model via Ollama API
	4.	ğŸ—£ï¸ Speaks the response using pyttsx3 text-to-speech

â¸»

ğŸ§ª To Run the Agent:

    Activate your virtual environment, then:
    python -m scripts.conversation_loop

This will start a loop that records â†’ transcribes â†’ asks the model â†’ replies back three times or until you say â€œexitâ€ / â€œbyeâ€ / â€œĞ²Ğ¸Ñ…Ñ–Ğ´â€.


ğŸ’¡ Notes:

	â€¢	The audio is saved temporarily as output.wav.
	â€¢	You can customize the number of turns or recording duration in the conversation_loop.py script.
	â€¢	The agent uses Whisper for transcription and pyttsx3 for TTS â€” everything runs locally.
